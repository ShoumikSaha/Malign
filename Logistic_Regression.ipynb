{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import csv\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_array_from_dataset(dest_file):\n",
    "    with open(dest_file,'r') as dest_f:\n",
    "        data_iter = csv.reader(dest_f,\n",
    "                               delimiter = ','\n",
    "                               )\n",
    "        data = [data for data in data_iter]\n",
    "    data_array = np.asarray(data)\n",
    "    \n",
    "    return data_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_array_type_int(data_array):\n",
    "    data_array = data_array[:, 1:]\n",
    "    data_array = np.asarray(data_array, dtype=int)\n",
    "    return data_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_array_from_dataset(dest_file):\n",
    "    data_array = return_array_from_dataset(dest_file)\n",
    "    data_array = change_array_type_int(data_array)\n",
    "    return data_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x1 = retrieve_array_from_dataset('Dataset_for_2.2/dataset_type1.csv')\n",
    "data_x2 = retrieve_array_from_dataset('Dataset_for_2.2/dataset_type2.csv')\n",
    "data_x3 = retrieve_array_from_dataset('Dataset_for_2.2/dataset_type3.csv')\n",
    "data_x4 = retrieve_array_from_dataset('Dataset_for_2.2/dataset_type4.csv')\n",
    "data_x5 = retrieve_array_from_dataset('Dataset_for_2.2/dataset_type5.csv')\n",
    "data_x6 = retrieve_array_from_dataset('Dataset_for_2.2/dataset_type6.csv')\n",
    "data_x7 = retrieve_array_from_dataset('Dataset_for_2.2/dataset_type7.csv')\n",
    "data_x8 = retrieve_array_from_dataset('Dataset_for_2.2/dataset_type8.csv')\n",
    "data_x9 = retrieve_array_from_dataset('Dataset_for_2.2/dataset_type9.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data_x1 = np.reshape(data_x1, (data_x1.shape[0], 27377, 2))\\ndata_x2 = np.reshape(data_x2, (data_x2.shape[0], 27377, 2))\\ndata_x3 = np.reshape(data_x3, (data_x3.shape[0], 27377, 2))\\ndata_x4 = np.reshape(data_x4, (data_x4.shape[0], 27377, 2))\\ndata_x5 = np.reshape(data_x5, (data_x5.shape[0], 27377, 2))\\ndata_x6 = np.reshape(data_x6, (data_x6.shape[0], 27377, 2))\\ndata_x7 = np.reshape(data_x7, (data_x7.shape[0], 27377, 2))\\ndata_x8 = np.reshape(data_x8, (data_x8.shape[0], 27377, 2))\\ndata_x9 = np.reshape(data_x9, (data_x9.shape[0], 27377, 2))'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''data_x1 = np.reshape(data_x1, (data_x1.shape[0], 27377, 2))\n",
    "data_x2 = np.reshape(data_x2, (data_x2.shape[0], 27377, 2))\n",
    "data_x3 = np.reshape(data_x3, (data_x3.shape[0], 27377, 2))\n",
    "data_x4 = np.reshape(data_x4, (data_x4.shape[0], 27377, 2))\n",
    "data_x5 = np.reshape(data_x5, (data_x5.shape[0], 27377, 2))\n",
    "data_x6 = np.reshape(data_x6, (data_x6.shape[0], 27377, 2))\n",
    "data_x7 = np.reshape(data_x7, (data_x7.shape[0], 27377, 2))\n",
    "data_x8 = np.reshape(data_x8, (data_x8.shape[0], 27377, 2))\n",
    "data_x9 = np.reshape(data_x9, (data_x9.shape[0], 27377, 2))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22, 54754)\n",
      "(275, 54754)\n"
     ]
    }
   ],
   "source": [
    "print(data_x3.shape)\n",
    "print(data_x4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = np.concatenate((data_x1, data_x2, data_x3, data_x4, data_x5, data_x6, data_x7, data_x8, data_x9), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(384, 54754)\n"
     ]
    }
   ],
   "source": [
    "print(data_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_y1 = np.zeros((53), dtype=int)\n",
    "data_y2 = np.ones((275), dtype=int)\n",
    "data_y3 = np.zeros((56), dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "(384,)\n"
     ]
    }
   ],
   "source": [
    "data_y = np.concatenate((data_y1, data_y2, data_y3), axis=0)\n",
    "print(data_y)\n",
    "print(data_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data_x, data_y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 0 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1\n",
      " 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1\n",
      " 1 1 1 1 0 1 0 1 0 1 0 1 1 1 0 0 1 0 1 0 1 0 0 1 1 1 1 0 1 1 1 1 1 0 0 1 1\n",
      " 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1 1 0 0 1 0 0 1 1 1 0 0 1\n",
      " 0 1 1 0 1 1 1 0 0 1 0 1 0 1 1 1 1 1 1 1 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 1 1\n",
      " 0 1 1 1 1 1 1 1 0 0 1 1 1 1 0 0 1 1 1 1 1 1 1 1 0 0 1 1 0 0 1 0 1 1 0 1 1\n",
      " 1 1 1 0 0 1 1 0 1 0 1 1 0 1 1 0 0 1 1 1 1 1 0 0 1 0 0 1 0 0 1 1 1 1 1 1 1\n",
      " 1 1 0 0 1 1 1 1 1 0 1]\n",
      "[1 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 0 0 0 0 0\n",
      " 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1\n",
      " 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(solver='liblinear', C=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.05, solver='liblinear')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.961038961038961"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "mat = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('Coefficients2.2.txt', model.coef_, fmt='%.4f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('Coefficients2.2(standardized).txt', model.coef_, fmt='%.4f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54754,)\n",
      "17601\n"
     ]
    }
   ],
   "source": [
    "coef = np.loadtxt('Coefficients2.2(standardized).txt')\n",
    "print(coef.shape)\n",
    "count = 0\n",
    "for i in range(1, coef.shape[0], 2):\n",
    "    if(coef[i]>0):\n",
    "        count += 1\n",
    "    #i += 2\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_performance():\n",
    "    file = open(\"performance_4_log_regression.txt\", \"w\")\n",
    "    tp = mat[0][0]\n",
    "    tn = mat[1][1]\n",
    "    fp = mat[0][1]\n",
    "    fn = mat[1][0]\n",
    "    \n",
    "    recall = tp/(tp+fn)\n",
    "    print(\"Recall/Sensitivity: \", recall)\n",
    "    file.write(\"Recall: \")\n",
    "    file.write(str(recall) + \"\\n\")\n",
    "    \n",
    "    specificity = tn/(tn+fp)\n",
    "    print(\"Specificity: \", specificity)\n",
    "    file.write(\"Specificity: \")\n",
    "    file.write(str(specificity) + \"\\n\")\n",
    "    \n",
    "    precision = tp/(tp+fp)\n",
    "    print(\"Precision: \", precision)\n",
    "    file.write(\"Precision: \")\n",
    "    file.write(str(precision) + \"\\n\")\n",
    "    \n",
    "    f1_score = (2*tp)/(2*tp + fp + fn)\n",
    "    print(\"F1 Score: \", f1_score)\n",
    "    file.write(\"F1 Score: \")\n",
    "    file.write(str(f1_score) + \"\\n\")\n",
    "    \n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall/Sensitivity:  0.9166666666666666\n",
      "Specificity:  1.0\n",
      "Precision:  1.0\n",
      "F1 Score:  0.9565217391304348\n"
     ]
    }
   ],
   "source": [
    "write_performance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
